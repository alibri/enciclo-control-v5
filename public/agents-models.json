{
  "openai": {
    "gpt-5.2": {
      "input": 1.75,
      "cached_input": 0.175,
      "output": 14.00,
      "max_tokens": 400000
    },
    "gpt-5.1": {
      "input": 1.25,
      "cached_input": 0.125,
      "output": 10.00,
      "max_tokens": 400000
    },
    "gpt-5": {
      "input": 1.25,
      "cached_input": 0.125,
      "output": 10.00,
      "max_tokens": 400000
    },
    "gpt-5-mini": {
      "input": 0.25,
      "cached_input": 0.025,
      "output": 2.00,
      "max_tokens": 400000
    },
    "gpt-5-nano": {
      "input": 0.05,
      "cached_input": 0.005,
      "output": 0.40,
      "max_tokens": 400000
    },
    "gpt-5.2-chat-latest": {
      "input": 1.75,
      "cached_input": 0.175,
      "output": 14.00,
      "max_tokens": 400000
    },
    "gpt-5.1-chat-latest": {
      "input": 1.25,
      "cached_input": 0.125,
      "output": 10.00,
      "max_tokens": 400000
    },
    "gpt-5-chat-latest": {
      "input": 1.25,
      "cached_input": 0.125,
      "output": 10.00,
      "max_tokens": 400000
    },
    "gpt-5.1-codex-max": {
      "input": 1.25,
      "cached_input": 0.125,
      "output": 10.00,
      "max_tokens": 400000
    },
    "gpt-5.1-codex": {
      "input": 1.25,
      "cached_input": 0.125,
      "output": 10.00,
      "max_tokens": 400000
    },
    "gpt-5-codex": {
      "input": 1.25,
      "cached_input": 0.125,
      "output": 10.00,
      "max_tokens": 400000
    },
    "gpt-5.2-pro": {
      "input": 21.00,
      "output": 168.00,
      "max_tokens": 400000
    },
    "gpt-5-pro": {
      "input": 15.00,
      "output": 120.00,
      "max_tokens": 400000
    },
    "gpt-4.1": {
      "input": 2.00,
      "cached_input": 0.50,
      "output": 8.00,
      "max_tokens": 1048576
    },
    "gpt-4.1-mini": {
      "input": 0.40,
      "cached_input": 0.10,
      "output": 1.60,
      "max_tokens": 1048576
    },
    "gpt-4.1-nano": {
      "input": 0.10,
      "cached_input": 0.025,
      "output": 0.40,
      "max_tokens": 1048576
    },
    "gpt-4o": {
      "input": 2.50,
      "cached_input": 1.25,
      "output": 10.00,
      "max_tokens": 128000
    },
    "gpt-4o-2024-05-13": {
      "input": 5.00,
      "output": 15.00,
      "max_tokens": 128000
    },
    "gpt-4o-mini": {
      "input": 0.15,
      "cached_input": 0.075,
      "output": 0.60,
      "max_tokens": 128000
    },
    "gpt-realtime": {
      "input": 4.00,
      "cached_input": 0.40,
      "output": 16.00,
      "max_tokens": 128000
    },
    "gpt-realtime-mini": {
      "input": 0.60,
      "cached_input": 0.06,
      "output": 2.40,
      "max_tokens": 128000
    },
    "gpt-4o-realtime-preview": {
      "input": 5.00,
      "cached_input": 2.50,
      "output": 20.00,
      "max_tokens": 128000
    },
    "gpt-4o-mini-realtime-preview": {
      "input": 0.60,
      "cached_input": 0.30,
      "output": 2.40,
      "max_tokens": 128000
    },
    "o1": {
      "input": 15.00,
      "cached_input": 7.50,
      "output": 60.00,
      "max_tokens": 128000
    },
    "o1-pro": {
      "input": 150.00,
      "output": 600.00,
      "max_tokens": 128000
    },
    "o3-pro": {
      "input": 20.00,
      "output": 80.00,
      "max_tokens": 128000
    },
    "o3": {
      "input": 2.00,
      "cached_input": 0.50,
      "output": 8.00,
      "max_tokens": 128000
    },
    "o4-mini": {
      "input": 1.10,
      "cached_input": 0.275,
      "output": 4.40,
      "max_tokens": 128000
    },
    "o3-mini": {
      "input": 1.10,
      "cached_input": 0.55,
      "output": 4.40,
      "max_tokens": 128000
    },
    "o1-mini": {
      "input": 1.10,
      "cached_input": 0.55,
      "output": 4.40,
      "max_tokens": 128000
    }
  },
  "gemini": {
    "gemini-2.0-flash": {
      "input": 0.10,
      "output": 0.40,
      "max_tokens": 1048576
    },
    "gemini-2.0-flash-lite": {
      "input": 0.075,
      "output": 0.300,
      "max_tokens": 1048576
    },
    "gemini-2.5-pro": {
      "input": 1.25,
      "output": 10.00,
      "max_tokens": 1048576
    },
    "gemini-2.5-flash": {
      "input": 0.30,
      "output": 2.50,
      "max_tokens": 1048576
    },
    "gemini-2.5-flash-lite": {
      "input": 0.10,
      "output": 0.40,
      "max_tokens": 1048576
    }
  }
}
